---
title: "MSADS 506 Final Project: Airline Baggage Complaints Time Series Data Analysis"
author: "Team 3: Logan Van Dine & UE Wang"
output: html_document
---

*Baggage - The total number of passenger complaints for theft of baggage contents, or for lost, damaged, or misrouted luggage for the airline that month

*Scheduled - The total number of flights scheduled by that airline that month

*Cancelled - The total number of flights cancelled by that airline that month

*Enplaned - The total number of passengers who boarded a plane with the airline that month

```{r}
# load the packages

library(readxl)
library(tidyverse)
library(fpp2)
library(zoo)
library(readr)
library(dplyr)
library(ggplot2)
library(forecast)
library(gridExtra)
library(reshape2) 
set.seed(506)
```

# Part 1: Exploratory Data Analysis

```{r}
df <- read_csv("/Users/UE/Desktop/baggagecomplaints.csv",
                col_types = cols(Date = col_date(format = "%m/%Y")))

df <- df %>%
  mutate(Baggage_Ratio = Baggage / Enplaned *100,
         Cancel_Ratio = Cancelled / Scheduled *100)
df
```

```{r}
summary(df)
```
      
```{r}
correlation_matrix <- cor(df[, c("Baggage", "Scheduled", "Cancelled", "Enplaned")])
correlation_matrix
```

```{r}
# Melt the correlation matrix into a long format suitable for plotting
correlation_melted <- melt(correlation_matrix)

# Create a heatmap using ggplot
heatmap <- ggplot(correlation_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "gray90", high = "gray20") +  
  labs(title = "Correlation Heatmap",
       x = "Variables",
       y = "Variables") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Display the heatmap
print(heatmap)
```

```{r}
# Create boxplots for each variable
boxplot_baggage <- ggplot(df, aes(y = Baggage)) +
  geom_boxplot(fill = "grey50", color = "black") +
  ggtitle("Baggage Complaints")+
  theme(plot.title = element_text(size = 8))

boxplot_scheduled <- ggplot(df, aes(y = Scheduled)) +
  geom_boxplot(fill = "grey50", color = "black") +
  ggtitle("Scheduled Flights")+
  theme(plot.title = element_text(size = 8))

boxplot_cancelled <- ggplot(df, aes(y = Cancelled)) +
  geom_boxplot(fill = "grey50", color = "black") +
  ggtitle("Cancelled Flights")+
  theme(plot.title = element_text(size = 8))

boxplot_enplaned <- ggplot(df, aes(y = Enplaned)) +
  geom_boxplot(fill = "grey50", color = "black") +
  ggtitle("Enplaned Flights")+
  theme(plot.title = element_text(size = 8))+
  scale_y_continuous(labels = scales::number_format(scale = 1e-6))

gridExtra::grid.arrange(boxplot_baggage, boxplot_scheduled, boxplot_cancelled, boxplot_enplaned, nrow = 1)
```

```{r}
# Create a time series for baggage complaints
bag <- ts(df$Baggage,start = c(2004, 01), end = c(2010, 12), frequency = 12)

# Plot the time series of baggage complaints
autoplot(bag) +
  theme_classic() +
  labs(x = "Time", y = "Baggage Content Complaints") +
  ggtitle("Baggage Complaint Over Time")
```

```{r}
# Combine the data for different airlines into one time series object
American_Eagle <- subset(df, Airline == 'American Eagle')
Hawaiian <- subset(df, Airline == 'Hawaiian')
United <- subset(df, Airline == 'United')

# Create time series objects for each airline
American_Eagle.ts <- ts(American_Eagle$Baggage, start = c(2004, 1), end = c(2010, 12), frequency = 12)
Hawaiian.ts <- ts(Hawaiian$Baggage, start = c(2004, 1), end = c(2010, 12), frequency = 12)
United.ts <- ts(United$Baggage, start = c(2004, 1), end = c(2010, 12), frequency = 12)

# Merge the time series data into one object
merged_ts <- cbind(American_Eagle = American_Eagle.ts, Hawaiian = Hawaiian.ts, United = United.ts)

# Plot the merged time series data
autoplot(merged_ts) +
  theme_classic() +
  labs(x = "Time", y = "Baggage Complaints") +
  ggtitle("Baggage Complaints Over Time")

```

```{r}
# Calculate baggage complaints per enplaned passenger for each airline
American_Eagle$Baggage_Ratio <- American_Eagle$Baggage / American_Eagle$Enplaned *100
Hawaiian$Baggage_Ratio <- Hawaiian$Baggage / Hawaiian$Enplaned *100
United$Baggage_Ratio <- United$Baggage / United$Enplaned *100

# Combine the ratios into one data frame
merged_ratios <- data.frame(
  American_Eagle = American_Eagle$Baggage_Ratio,
  Hawaiian = Hawaiian$Baggage_Ratio,
  United = United$Baggage_Ratio)

# Convert merged ratios into a time series object
merged_Baggage_Ratio <- ts(merged_ratios, start = c(2004, 1), end = c(2010, 12), frequency = 12)

# Plot the merged ratio time series data
autoplot(merged_Baggage_Ratio) +
  theme_classic() +
  labs(x = "Time", y = "Baggage Complaints per Enplaned Passenger") +
  ggtitle("Baggage Complaints per Enplaned Passenger Over Time")

```


```{R}
# Calculate canceled flights per scheduled flight for each airline
American_Eagle$Cancel_Ratio <- American_Eagle$Cancelled / American_Eagle$Scheduled *100
Hawaiian$Cancel_Ratio <- Hawaiian$Cancelled / Hawaiian$Scheduled *100
United$Cancel_Ratio <- United$Cancelled / United$Scheduled *100

# Combine the ratios into one data frame
merged_Cancel_ratios <- data.frame(
  American_Eagle = American_Eagle$Cancel_Ratio,
  Hawaiian = Hawaiian$Cancel_Ratio,
  United = United$Cancel_Ratio)

# Convert merged ratios into a time series object
merged_Cancel_Ratio <- ts(merged_Cancel_ratios, start = c(2004, 1), end = c(2010, 12), frequency = 12)

# Plot the merged ratio time series data
autoplot(merged_Cancel_Ratio) +
  theme_classic() +
  labs(x = "Time", y = "Canceled Flight divided by Scheduled") +
  ggtitle("Canceled Flights per Scheduled Flight Over Time")
```

```{r}
# Create a time series for the baggage per enplaned ratio
bag_ratio.ts <- ts(df$Baggage_Ratio,start = c(2004, 01), end = c(2010, 12), frequency = 12)

# Plot the time series of baggage per enplaned ratio
autoplot(bag_ratio.ts) +
  theme_classic() +
  labs(x = "Time", y = "Baggage per Enplaned Ratio") +
  ggtitle("Baggage per Enplaned Ratio Over Time")
```

```{r}
# Create a time series for the flight cancellation ratio
Cancel_Ratio.ts <- ts(df$Cancel_Ratio,start = c(2004, 01), end = c(2010, 12), frequency = 12)

# Plot the time series of flight cancellation ratio
autoplot(Cancel_Ratio.ts) +
  theme_classic() +
  labs(x = "Time", y = "Flight Cancel Ratio") +
  ggtitle("Flight Cancellation Ratio Over Time")
```



```{r}
# Decompose the time series 'bag' using seasonal-trend decomposition
stl.bag <- stl(bag, s.window = "periodic")

# Plot the components of the decomposition
plot(stl.bag)
```

```{r}
# Decompose the time series 'bag_ratio.ts' using seasonal-trend decomposition
stl.bag_ratio <- stl(bag_ratio.ts, s.window = "periodic")
plot(stl.bag_ratio)
```


```{r}
# Decompose the time series 'Cancel_Ratio.ts' using seasonal-trend decomposition
stl.Cancel_Ratio <- stl(Cancel_Ratio.ts, s.window = "periodic")
plot(stl.Cancel_Ratio)
```

# Part 2: Data Preprocessing

```{r}
df <- read_csv("/Users/UE/Desktop/baggagecomplaints.csv",
                col_types = cols(Date = col_date(format = "%m/%Y")))
df
```

```{r}
bag.ts <- ts(df$Baggage,start = c(2004, 01), end = c(2010, 12), frequency = 12)

autoplot(bag.ts) +
  theme_classic() +
  labs(x = "Time", y = "Baggage Complaint Over Time")
```

```{r}
# Calculate moving averages
bag.ts.trailing <- rollmean(bag.ts, k = 12, align = "right")
bag.ts.ma.centered <- rollmean(bag.ts, k = 12, fill = NA)  # Using rollmean for centered moving average

# Plotting
plot(bag.ts, ylim = c(1000, 35000), ylab = "Baggage", xlab = "Time", bty = "n", xaxt = "n",
     xlim = c(2004, 2010), main = "")
axis(1, at = seq(2004, 2010, 1), labels = seq(2004, 2010, 1))
lines(bag.ts.ma.centered, lwd = 2, col = "blue")  
lines(bag.ts.trailing, lwd = 2, lty = 2, col = "red") 

# Adding legend
legend("topright", legend = c("Baggage Complaint", "Centered Moving Average", "Trailing Moving Average"),
       lty = c(1, 1, 2), lwd = c(1, 2, 2), col = c("black", "blue", "red"))
```

moving average does not work well with the data that have trend or seasonality. The  moving average does not capture the seasonality in the data. Seasons with high baggage complaints are under-forecasted, and seasons with low baggage complaints are over-forecasted.

```{r}
# Create a training and test set
#diff.twice.ts <- diff(diff(bag.ts, lag = 12), lag = 4)
training.ts <- window(bag.ts, start = c(2004, 01), end = c(2010, 06))
test.ts <- window(bag.ts, start = c(2010, 07), end = c(2010, 12))
```

# Part 3: Modeling

simple exponential smoothing model

```{r}
ses <- ets(training.ts, model = "ANN", alpha = 0.2)
ses.pred <- forecast(ses, h = 6, level = 0)
ses.pred

plot(ses.pred, ylim = c(1000, 35000),  ylab = "Baggage Complaints (Twice-Differenced)", xlab = "Time",
    bty = "l", xaxt = "n", xlim = c(2004, 2011), main = "", flty = 2)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(ses.pred$fitted, lwd = 2, col = "blue")
lines(test.ts)
```

```{r}
accuracy(ses.pred$mean, test.ts)
```

Holt-Winterâ€™s exponential smoothing model 

```{r}
hwin <- ets(training.ts, model = "MAA")
hwin.pred <- forecast(hwin, h = 6, level = 0)

plot(hwin.pred, ylim = c(1000, 35000), ylab = "Baggage Complaints", xlab = "Time",
     bty = "l", xaxt = "n", xlim = c(2004, 2011), main = "", flty = 2)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(hwin.pred$fitted, lwd = 2, col = "blue")
lines(test.ts)
```

```{r}
accuracy(hwin.pred$mean, test.ts)
```

STL + ARIMA 

```{r}
# Fit the STL + ARIMA model
stlm.reg.fit <- stlm(training.ts, s.window = "periodic", method = "arima")

# Forecast using the trained model
stlm.reg.pred <- forecast(stlm.reg.fit, h = length(test.ts))

# Plot the forecast
plot(stlm.reg.pred, xlab = "Year", ylab = "Weekly Sales")
```

```{r}
accuracy(stlm.reg.pred$mean, test.ts)
```

Neural network autoregression

```{r}
set.seed(201)

bag.nnetar <- nnetar(training.ts, repeats = 20, p = 11, P = 1, size = 3)
summary(bag.nnetar$model[[1]])
bag.nnetar.pred <- forecast(bag.nnetar, h = 6)
accuracy(bag.nnetar.pred, test.ts)
plot(training.ts, ylim = c(1000, 35000),  ylab = "Baggage Complaints", xlab = "Time",
    bty = "l", xaxt = "n", xlim = c(2004, 2011), lty = 1)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(bag.nnetar.pred$fitted, lwd = 2, col = "blue")
lines(bag.nnetar.pred$mean, lwd = 2, col = "blue", lty = 2)
lines(test.ts)
```

```{r}
accuracy(bag.nnetar.pred$mean, test.ts)
```

```{r}
library(knitr)

# Your accuracy_table data frame
accuracy_table <- data.frame(
  Model = c("Simple exponential smoothing", "Holt-Winter", "STL + ARIMA", "Neural network autoregression"),
  ME = c(-432.5183, 45.45592, 850.5374, 752.8873 ),
  RMSE = c(1262.605, 1864.611, 2047.311, 1303.213),
  MAE = c(1061.951, 1706.882, 1768.298, 861.1778),
  MPE = c(-6.236093, 2.874442, 11.61096, 7.345394),
  MAPE = c(11.74719, 18.38551, 20.11946, 8.619699),
  ACF1 = c(-0.1278269, -0.16718, -0.1133736, 0.186985),
  Theils_U = c(0.8029777, 1.151863, 1.264255, 0.8650974)
)

# Printing the table using kable with formatting adjustments
cat(kable(accuracy_table, caption = "Accuracy Metrics for Different Models", format = "markdown"),
    sep = "\n")
```

While Simple Exponential Smoothing (SES) demonstrates a lower RMSE, its limitation in effectively capturing seasonality might compromise the accuracy of forecasts, especially when dealing with data heavily influenced by seasonal patterns.

Holt-Winterâ€™s Exponential Smoothing (HWIN) offers an advantage over SES. With its explicit capability to handle seasonality and a lower RMSE compared to STL + ARIMA and Neural Network Autoregression, HWIN emerges as a more suitable choice for forecasting in scenarios where accurate representation of seasonal patterns is pivotal. The ability of HWIN to capture these intricate patterns provides it with a distinct edge over SES. Prioritizing this accuracy in seasonal depiction is crucial, making HWIN a preferred option for such forecasting tasks.

Holt-Winter's for each Airline:

Holt-Winterâ€™s exponential smoothing model for American Egle:

```{r}
AE_training.ts <- window(American_Eagle.ts, start = c(2004, 01), end = c(2010, 06))
AE_test.ts <- window(American_Eagle.ts, start = c(2010, 07), end = c(2010, 12))
AE_hwin <- ets(AE_training.ts, model = "MAA")
AE_hwin.pred <- forecast(AE_hwin, h = 6, level = 0)

plot(AE_hwin.pred, ylim = c(1000, 35000), ylab = "American Eagle Baggage Complaints", xlab = "Time",
     bty = "l", xaxt = "n", xlim = c(2004, 2011), main = "", flty = 2)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(AE_hwin.pred$fitted, lwd = 2, col = "blue")
lines(AE_test.ts)
```

```{r}
accuracy(AE_hwin.pred$mean, AE_test.ts)
```

Holt-Winterâ€™s exponential smoothing model for United Airline:

```{r}
UA_training.ts <- window(United.ts, start = c(2004, 01), end = c(2010, 06))
UA_test.ts <- window(United.ts, start = c(2010, 07), end = c(2010, 12))
UA_hwin <- ets(UA_training.ts, model = "MAA")
UA_hwin.pred <- forecast(UA_hwin, h = 6, level = 0)

plot(UA_hwin.pred, ylim = c(1000, 45000), ylab = "United Airline Baggage Complaints", xlab = "Time",
     bty = "l", xaxt = "n", xlim = c(2004, 2011), main = "", flty = 2)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(UA_hwin.pred$fitted, lwd = 2, col = "blue")
lines(UA_test.ts)
```
```{r}
accuracy(UA_hwin.pred$mean, UA_test.ts)
```

Holt-Winterâ€™s exponential smoothing model for Hawaiian Airline:

```{r}
HA_training.ts <- window(Hawaiian.ts, start = c(2004, 01), end = c(2010, 06))
HA_test.ts <- window(Hawaiian.ts, start = c(2010, 07), end = c(2010, 12))
HA_hwin <- ets(HA_training.ts, model = "MAA")
HA_hwin.pred <- forecast(HA_hwin, h = 6, level = 0)

plot(HA_hwin.pred, ylim = c(500, 3500), ylab = "Hawaiian Airline Baggage Complaints", xlab = "Time",
     bty = "l", xaxt = "n", xlim = c(2004, 2011), main = "", flty = 2)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(HA_hwin.pred$fitted, lwd = 2, col = "blue")
lines(HA_test.ts)
```

```{r}
accuracy(HA_hwin.pred$mean, HA_test.ts)
```

Try Other models for Hawaiian Airline:

STL + ARIMA 

```{r}
# Fit the STL + ARIMA model
ha.stlm.reg.fit <- stlm(HA_training.ts, s.window = "periodic", method = "arima")

# Forecast using the trained model
ha.stlm.reg.pred <- forecast(ha.stlm.reg.fit, h = length(HA_test.ts))

# Plot the forecast
plot(ha.stlm.reg.pred, xlab = "Year", ylab = "Weekly Sales")
```

```{r}
accuracy(ha.stlm.reg.pred$mean, HA_test.ts)
```

simple exponential smoothing model

```{r}
ha.diff.twice.ts <- diff(diff(bag.ts, lag = 12), lag = 4)

ha.ses <- ets(HA_training.ts, model = "ANN", alpha = 0.2)
ha.ses.pred <- forecast(ha.ses, h = 6, level = 0)
ha.ses.pred

plot(ha.ses.pred, ylim = c(500, 3500),  ylab = "Hawaiian Airline Baggage Complaints (Twice-Differenced)", xlab = "Time",
    bty = "l", xaxt = "n", xlim = c(2004, 2011), main = "", flty = 2)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(ha.ses.pred$fitted, lwd = 2, col = "blue")
lines(HA_test.ts)
```

```{r}
accuracy(ha.ses.pred$mean, HA_test.ts)
```

Neural network autoregression for Hawaiian Airline

```{r}
set.seed(201)

ha.nnetar <- nnetar(HA_training.ts, repeats = 20, p = 11, P = 1, size = 3)
summary(ha.nnetar$model[[1]])
ha.nnetar.pred <- forecast(ha.nnetar, h = 6)
accuracy(ha.nnetar.pred, HA_test.ts)
plot(HA_training.ts, ylim = c(500, 3500),  ylab = "Hawaiian Airline Baggage Complaints", xlab = "Time",
    bty = "l", xaxt = "n", xlim = c(2004, 2011), lty = 1)
axis(1, at = seq(2004, 2011, 1), labels = format(seq(2004, 2011, 1)))
lines(ha.nnetar.pred$fitted, lwd = 2, col = "blue")
lines(ha.nnetar.pred$mean, lwd = 2, col = "blue", lty = 2)
lines(HA_test.ts)
```

```{r}
library(knitr)
# Assuming you have the data in variables like this:
HA_data <- data.frame(
  Method = c("Holt-Winter", "STL + ARIMA", "Simple exponential smoothing", "Neural network autoregression"),
  ME = c(653.7532, 506.2353, 658.8911, 458.7076),
  RMSE = c(873.2616, 724.8699, 820.6329, 612.2804),
  MAE = c(739.4063, 635.6922, 658.8911, 493.0974),
  MPE = c(27.89336, 20.56007, 29.53305, 19.70227),
  MAPE = c(34.23057, 30.24288, 29.53305, 22.38269),
  ACF1 = c(0.3953068, 0.3674934, 0.318373, 0.1983688),
  Theils_U = c(1.841316, 1.53408, 1.671758, 1.267417)
)

# Printing the table using kable
#knitr::kable(data, caption = "Accuracy Metrics for Different Methods")
cat(kable(HA_data, caption = "Hawaiian Airline Accuracy Metrics for Different Models", format = "markdown"),
    sep = "\n")
```

The neural network model exhibits the lowest Mean Error (ME) and Root Mean Squared Error (RMSE), suggesting superior performance in minimizing overall prediction errors. However, it's important to note that neural networks have a tendency to overfit data, which might limit its generalizability to new data.

On the other hand, the STL+ARIMA model showcases robust performance and emerges as a strong contender. It doesn't boast the absolute lowest values in every single metric, yet it strikes a well-balanced performance across multiple criteria. Particularly, it demonstrates lower values in RMSE, Mean Absolute Error (MAE), and Mean Percentage Error (MPE), showcasing its capability to provide accurate and stable forecasts. Moreover, 'STL+ARIMA' exhibits lower Mean Absolute Percentage Error (MAPE), which is pivotal for accuracy in percentage terms, further solidifying its credibility as a reliable forecasting model. Considering its well-rounded performance and ability to avoid overfitting issues, 'STL+ARIMA' appears to be the most promising choice among the presented models.